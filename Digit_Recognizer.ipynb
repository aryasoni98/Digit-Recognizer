{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1QtO3VDjEKTdCudfhXSkG0ZuxBdjnP4ZG",
      "authorship_tag": "ABX9TyM8dJ6JqPOrm5kcZC/yIQCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryasoni98/Digit-Recognizer/blob/main/Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQI3jartyMOw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svK4m0fwyjOe"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Dataset/digit-recognizer/train.csv')\n",
        "labels = data.pop('label').to_numpy()\n",
        "data = data.to_numpy().reshape(-1,28,28)\n",
        "\n",
        "data = np.expand_dims(data,axis=-1)\n",
        "labels = np.expand_dims(labels,axis=-1)\n",
        "\n",
        "data = tf.pad(data,[[0,0],[2,2],[2,2],[0,0]])\n",
        "\n",
        "num = data.shape[0] // 10\n",
        "train_data, val_data, test_data = tf.split(data,[num*8, num, num])\n",
        "train_label, val_label, test_label = tf.split(labels,[num*8, num, num])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_data,train_label)).shuffle(33600,seed=42).batch(128)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_data,val_label)).shuffle(33600,seed=42).batch(128)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_data,test_label)).shuffle(33600,seed=42).batch(128)\n",
        "\n",
        "image_shape = (32,32,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EsZ_-qY4uY6"
      },
      "source": [
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58otVhoe4xSc"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Y2geZB406S"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0yvPXy44Hh"
      },
      "source": [
        "def ResNet(input_shape=(224, 224, 3)):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "    \n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "base_model = ResNet(input_shape=image_shape)\n",
        "headModel = base_model.output\n",
        "headModel = Flatten()(headModel)\n",
        "headModel=Dense(400, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel=Dense(300, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "headModel = Dense( 10,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
        "model = Model(inputs=base_model.input, outputs=headModel)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxNUaQp547hs"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr=0.0001),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "checkpointer_best_train = ModelCheckpoint(\n",
        "    filepath='./final_model3.h5',\n",
        "    monitor='loss', verbose=1, save_best_only=True, mode='min'\n",
        ")\n",
        "\n",
        "callback_list = [checkpointer_best_train]\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',\n",
        "                                    patience=10,restore_best_weights=True)\n",
        "\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode='max',factor=0.5,patience=5)\n",
        "\n",
        "history = model.fit(train_ds,batch_size=64 ,epochs=110,validation_data=val_ds,\n",
        "                    callbacks=callback_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfha1AcR5E6p"
      },
      "source": [
        "history = model.fit(train_ds,batch_size=64 ,epochs=2,validation_data=val_ds,\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x-n-gir_ka6"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_SwPgUJ_tOo"
      },
      "source": [
        "model.evaluate(test_ds,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v00TL_lW_yvm"
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/Dataset/digit-recognizer/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/Dataset/digit-recognizer/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "957mkWwZAKfI"
      },
      "source": [
        "test = test.to_numpy().reshape(-1,28,28)\n",
        "test = np.expand_dims(test,axis=-1)\n",
        "test = tf.pad(test,[[0,0],[2,2],[2,2],[0,0]])\n",
        "\n",
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC8DXjUOANWk"
      },
      "source": [
        "sample_submission.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlRQlAhKAPre"
      },
      "source": [
        "result =  model.predict(test)\n",
        "\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vwpYiAIARi4"
      },
      "source": [
        "predict_label = np.argmax(result,axis=-1)\n",
        "\n",
        "predict_label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuGi4kr2AT7l"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(test[i,...,0])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.xlabel(predict_label[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4BcoAeqAWdF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}